{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\paperw11900\paperh16840\margl1440\margr1440\vieww28300\viewh17700\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 COMP9417 - Assignment 2\
\
Group:\
	1) Nihit Vyas (z5140232)\
	2) James Holman (z5143237)\
	3) Vidika Badal (z5129296)\
\
This is an implementation of Convolutional Neural Network based Human Emotions Recognition System. \
The code is available in files.zip file together with the report.pdf. \
\

\b Dataset: 
\b0 \
\
The dataset used for this project is the FER-2013 Facial Expression Recognition Challenge from Kaggle. The dataset consists of 28,709 pictures of human faces with seven different emotions (happy, neutral, angry, disgusted, fearful, sad, surprised). \
The dataset and the trained model files are available at - https://drive.google.com/open?id=1tsO3sWSDCYJqKmM7wBy3XNcRS3q1ZVwQ\
The Google Drive also contains the copy of the code and the virtual environment.\
\

\b Usage
\b0 \
The code for training and testing is available in the submitted files. The dependencies are listed in requirements.txt In order to test/run, download and extract the files from Google Drive and follow the instructions-\
\pard\tx220\tx720\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\li720\fi-720\pardirnatural\partightenfactor0
\ls1\ilvl0\cf0 {\listtext	\uc0\u8226 	}If using the virtual environment run - pip3 install virtualenv \
{\listtext	\uc0\u8226 	}If running without the virtual environment install dependencies from the requirements.txt file: pip3 install -r requirements.txt\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
1) in the directory activate the virtual-environment by typing:\
	\
	source mlproj/bin/activate\
\
    The virtual environment comes with all dependencies installed for python 3.6.\
\
2) The dataset in the csv file needs to be transformed to generate image and label data. Run-\
	\
	python3 csv_to_numpy.py\
	\
3) To train the model -\
	\
	python3 emo_recogniser.py train\
\
4) To test the trained model (webcam required) -\
	\
	python3 run_emotion_recognizer.py \
\
}